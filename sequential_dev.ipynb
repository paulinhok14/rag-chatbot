{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL = 'llama2'\n",
    "\n",
    "file_path = os.path.join(os.path.dirname(__file__), r'src\\databases\\Bizuario Geral.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings()\n",
    "\n",
    "model.invoke('Me conte uma piada')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "# Adaptar para ler docx ou converter para pdf?\n",
    "\n",
    "loader = Docx2txtLoader(file_path)\n",
    "bizuario_doc = loader.load_and_split()\n",
    "bizuario_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Prompt (System Message. Define Tasks, Tone, Behaviour and Safety params)\n",
    "template = '''\n",
    "Você é um assistente virtual de uma área de materiais chamada Spare Parts Planning.\n",
    "Sua função será responder à questões genéricas feitas pelos colaboradores da área.\n",
    "Vou lhe passar um documento com diversas informações relevantes, tais como significado de siglas, telefones úteis, explicação de processos, etc, para que você use como referência para responder ao questionamento do usuário.\n",
    "\n",
    "Siga todas as regras abaixo:\n",
    "1/ Você deve buscar se comportar de maneira sempre cordial e solícita para atender aos questionamentos dos usuários.\n",
    "\n",
    "2/ Algumas linhas do documento fornecido podem conter informações irrelevantes. Preste atenção ao conteúdo útil da mensagem.\n",
    "\n",
    "3/ Existem informações pessoais dos colaboradores no documento, tais como número de telefone, evite passá-las sob quaisquer circunstâncias.\n",
    "A única informação que pode ser passada relacionada aos colaboradores é o respectivo login.\n",
    "\n",
    "4/ Em hipótese alguma envolva-se em discussões de cunho pessoal, sobre tecer opiniões sobre um colaborador ou outro. Caso a pergunta seja neste sentido, recuse-se gentilmente a opinar e ofereça ao usuário ajuda nas questões relevantes.\n",
    "\n",
    "Aqui está uma pergunta recebida de um usuário.\n",
    "{question}\n",
    "\n",
    "Aqui está o documento com as informações relevantes mencionadas.\n",
    "Esse arquivo servirá de base para que você compreenda nosso contexto de negócio, organização e nossas siglas mais comumente utilizadas.\n",
    "{bizuario_document}\n",
    "\n",
    "Escreva a melhor resposta que atende ao questionamento do usuário:\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context='Here is some context', question='Here is a question'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "    'context': 'O nome que me foi dado é Paulo',\n",
    "    'question': 'Qual o meu nome?'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part, VectorStore will be saved in memory only for concluding goals purpose. When developing the app, a fixed store should\n",
    "# be implemented. Such as sqlite, postgresql or something like that\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(bizuario_doc, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke('O que significa EPEP?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'context': itemgetter('question') | retriever,\n",
    "        'question': itemgetter('question')\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "chain.invoke({'question': 'O que significa EPEP?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install docarray\n",
    "#pydantic==1.10.8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
